The task is complete. Let me provide a summary of what was created.

## Summary

I created `/home/erikg/elman-proofs/ElmanProofs/Expressivity/TC0VsUnboundedRNN.lean` which formalizes the correct computational hierarchy:

**Linear SSM ⊊ TC0 (Transformers) ⊊ E88 (unbounded T) ⊆ RE**

This **reverses** the naive "Transformer > SSM > RNN" ordering!

### Key Results Formalized:

1. **`linear_ssm_cannot_parity`** - Linear SSMs (Mamba2, MinGRU) cannot compute running parity, placing them below TC0

2. **`parity_in_TC0`** - PARITY can be computed by constant-depth threshold circuits (TC0)

3. **`linear_ssm_strictly_below_TC0`** - The separation is witnessed by PARITY: Linear SSMs cannot compute it, but TC0 can

4. **`e88_depth_unbounded`** - E88 effective depth D×T grows unboundedly with sequence length T

5. **`TC0_strictly_below_e88_unbounded`** - For any constant depth bound C, E88 can exceed it

6. **`main_hierarchy`** - The complete hierarchy theorem proving:
   - Linear SSM < TC0 (PARITY separation)
   - TC0 < E88 (depth separation)
   - E88 bounded below RE (fixed state dimension)

### Key Insight:

The fundamental difference is **compositional depth**:
- Transformers: D layers = O(D) depth (constant in sequence length)
- Linear SSMs: D layers = O(D) depth (linear state collapses per layer)  
- E88: D layers × T steps = O(D×T) depth (tanh compounds across time)

For tasks requiring depth f(T), only E88 can handle f(T) = O(T) while TC0/Transformers are limited to constant depth.
