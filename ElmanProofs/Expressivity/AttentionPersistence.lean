/-
Copyright (c) 2026 Elman Project. All rights reserved.
Released under Apache 2.0 license.
Authors: Elman Project Contributors
-/
import Mathlib.LinearAlgebra.Matrix.NonsingularInverse
import Mathlib.Data.Matrix.Basic
import Mathlib.Analysis.Normed.Group.Basic
import Mathlib.Analysis.SpecialFunctions.Trigonometric.Basic
import Mathlib.Analysis.SpecialFunctions.Trigonometric.DerivHyp
import Mathlib.Analysis.Calculus.Deriv.MeanValue
import Mathlib.Analysis.Calculus.MeanValue
import Mathlib.Topology.Order.Basic
import Mathlib.Topology.Order.MonotoneConvergence
import Mathlib.Data.Finset.Basic
import Mathlib.Order.Filter.Basic
import Mathlib.Analysis.Complex.ExponentialBounds
import ElmanProofs.Activations.Lipschitz
import ElmanProofs.Expressivity.LinearCapacity
import ElmanProofs.Expressivity.LinearLimitations
import ElmanProofs.Expressivity.NumericalBounds

/-!
# Attention Persistence: Alert Mode Latching in E88

This file formalizes **attention persistence**, the key property that allows E88
heads to enter an "alert" state and maintain it indefinitely. This is analogous
to a finite state machine entering an absorbing state.

## Key Insight

The tanh function has saturation: as |x| â†’ âˆ, tanh(x) â†’ Â±1 and tanh'(x) â†’ 0.
This creates stable fixed points. For the recurrence S_{t+1} = tanh(Î±S_t + input):

1. **Fixed points exist**: For appropriate Î±, there exist S* with tanh(Î±S*) = S*
2. **Stability**: Near these fixed points, the derivative is small, creating basins
3. **Latching**: Once |S| is large, it stays large (the "alert" state persists)

## Main Results

### Fixed Point Analysis
* `tanh_recurrence_has_fixed_point` - tanh(Î±Â·S) = S has solutions for Î± â‰¥ 1
* `nonzero_fixed_point_exists` - For Î± > 1, nonzero fixed points exist
* `fixed_point_is_attractive` - Fixed points are locally stable attractors

### Alert State Basin
* `alert_threshold_exists` - There exists Î¸ such that |S| > Î¸ implies persistence
* `alert_state_forward_invariant` - Alert states remain alert under tanh iteration
* `alert_basin_nonempty` - The alert basin is non-empty

### Persistence Properties
* `latched_state_persists_under_perturbation` - Small perturbations don't knock out
* `attention_persistence_theorem` - Main result: E88 heads can latch and persist
* `linear_cannot_latch` - Linear systems have no stable nonzero fixed points

## Connection to E88 Architecture

In E88, each head has the update rule:
```
S_t := tanh(Î±Â·S_{t-1} + Î´Â·input_t)
```

When a head detects a relevant pattern (large Î´Â·input), its state can jump into
the "alert" region (|S| close to 1). Due to tanh saturation, this alert state
persists even when subsequent inputs are small.

This is the formal mechanism behind **attention persistence**: the head "pays
attention" to a feature and continues to remember it, unlike linear systems
where information decays.

-/

namespace AttentionPersistence

open Real Matrix Finset BigOperators Filter

/-! ## Part 1: Basic Tanh Recurrence Properties -/

/-- The tanh recurrence function: S â†’ tanh(Î±Â·S).
    This is the simplified E88 update with no input. -/
noncomputable def tanhRecur (Î± : â„) (S : â„) : â„ := tanh (Î± * S)

/-- Iterated tanh recurrence: applying tanhRecur n times. -/
noncomputable def tanhRecurIter (Î± : â„) : â„• â†’ â„ â†’ â„
  | 0, S => S
  | n + 1, S => tanhRecur Î± (tanhRecurIter Î± n S)

/-- The identity tanhRecurIter n+1 S = tanhRecur Î± (tanhRecurIter n S). -/
theorem tanhRecurIter_succ (Î± : â„) (n : â„•) (S : â„) :
    tanhRecurIter Î± (n + 1) S = tanhRecur Î± (tanhRecurIter Î± n S) := rfl

/-- tanhRecur preserves the bounded interval (-1, 1). -/
theorem tanhRecur_bounded (Î± : â„) (S : â„) : |tanhRecur Î± S| < 1 := by
  simp only [tanhRecur]
  exact Activation.tanh_bounded (Î± * S)

/-- tanhRecur is strictly monotone for Î± > 0 (since tanh is strictly monotone). -/
theorem tanhRecur_strictMono (Î± : â„) (hÎ± : 0 < Î±) : StrictMono (tanhRecur Î±) := by
  intro x y hxy
  simp only [tanhRecur]
  apply Activation.tanh_strictMono
  exact mul_lt_mul_of_pos_left hxy hÎ±

/-- tanhRecur is continuous. -/
theorem tanhRecur_continuous (Î± : â„) : Continuous (tanhRecur Î±) := by
  unfold tanhRecur
  -- tanh is Lipschitz hence continuous, and composition with linear is continuous
  have h_lip := Activation.tanh_lipschitz
  exact h_lip.continuous.comp (continuous_mul_left Î±)

/-! ## Part 2: Fixed Point Existence -/

/-- A fixed point of tanhRecur Î± is a solution to tanh(Î±S) = S. -/
def isFixedPoint (Î± : â„) (S : â„) : Prop := tanhRecur Î± S = S

/-- Zero is always a fixed point: tanh(0) = 0. -/
theorem zero_is_fixed_point (Î± : â„) : isFixedPoint Î± 0 := by
  simp [isFixedPoint, tanhRecur, tanh_zero]

/-- For Î± â‰¤ 1, zero is the only fixed point.
    Key insight: The derivative of tanh(Î±x) at x=0 is Î±Â·tanh'(0) = Î±Â·1 = Î±.
    For Î± â‰¤ 1, the curve y = tanh(Î±x) stays below y = x for x > 0. -/
theorem unique_fixed_point_for_small_alpha (Î± : â„) (hÎ±_pos : 0 < Î±) (hÎ±_le : Î± â‰¤ 1) :
    âˆ€ S : â„, isFixedPoint Î± S â†’ S = 0 := by
  intro S hS
  simp only [isFixedPoint, tanhRecur] at hS
  -- hS : tanh(Î±S) = S
  -- For S > 0: tanh(Î±S) < Î±S â‰¤ S since tanh(x) < x for x > 0 and Î± â‰¤ 1
  -- For S < 0: tanh(Î±S) > Î±S â‰¥ S by symmetry
  -- Only S = 0 works
  by_contra h_ne
  rcases lt_trichotomy S 0 with h_neg | h_zero | h_pos
  Â· -- S < 0 case
    have h1 : Î± * S < 0 := mul_neg_of_pos_of_neg hÎ±_pos h_neg
    have h2 : tanh (Î± * S) > Î± * S := by
      -- tanh(x) > x for x < 0
      -- Use oddness: tanh(x) = -tanh(-x), and for -x > 0, tanh(-x) < -x
      have h_neg_arg : 0 < -(Î± * S) := by linarith
      -- For -(Î±*S) > 0: tanh(-(Î±*S)) < -(Î±*S)
      have h_pos_case : tanh (-(Î± * S)) < -(Î± * S) := by
        -- Apply MVT on [0, -(Î±*S)]
        have h_cont : ContinuousOn tanh (Set.Icc 0 (-(Î± * S))) :=
          Activation.differentiable_tanh.continuous.continuousOn
        have h_diff : DifferentiableOn â„ tanh (Set.Ioo 0 (-(Î± * S))) :=
          Activation.differentiable_tanh.differentiableOn
        obtain âŸ¨c, âŸ¨hc_gt, hc_ltâŸ©, h_mvtâŸ© := exists_deriv_eq_slope tanh h_neg_arg h_cont h_diff
        rw [tanh_zero, sub_zero, sub_zero] at h_mvt
        have h_deriv_c_lt : deriv tanh c < 1 := by
          rw [Activation.deriv_tanh]
          have h_tanh_c_ne : tanh c â‰  0 := by
            intro heq_c
            have h_c_eq_0 : c = 0 := Activation.tanh_injective (heq_c.trans tanh_zero.symm)
            linarith
          have h_sq_pos : 0 < (tanh c)^2 := sq_pos_of_ne_zero h_tanh_c_ne
          linarith
        have h_ne : -(Î± * S) â‰  0 := ne_of_gt h_neg_arg
        have h_slope : tanh (-(Î± * S)) = deriv tanh c * (-(Î± * S)) := by
          field_simp at h_mvt
          linarith
        calc tanh (-(Î± * S)) = deriv tanh c * (-(Î± * S)) := h_slope
          _ < 1 * (-(Î± * S)) := mul_lt_mul_of_pos_right h_deriv_c_lt h_neg_arg
          _ = -(Î± * S) := one_mul _
      -- Now use tanh(-x) = -tanh(x)
      rw [tanh_neg] at h_pos_case
      linarith
    have h3 : Î± * S â‰¥ S := by
      -- Î±S â‰¥ S â†” S(Î±-1) â‰¥ 0
      -- S < 0 and Î± - 1 â‰¤ 0, so S(Î±-1) â‰¥ 0
      nlinarith
    -- From h2: tanh(Î±S) > Î±S, and h3: Î±S â‰¥ S
    -- So tanh(Î±S) > S, contradicting hS: tanh(Î±S) = S
    linarith
  Â· exact absurd h_zero h_ne
  Â· -- S > 0 case
    have h1 : 0 < Î± * S := mul_pos hÎ±_pos h_pos
    have h2 : tanh (Î± * S) < Î± * S := by
      -- tanh(x) < x for x > 0 by MVT
      -- Apply MVT on [0, Î±*S]
      have h_cont : ContinuousOn tanh (Set.Icc 0 (Î± * S)) :=
        Activation.differentiable_tanh.continuous.continuousOn
      have h_diff : DifferentiableOn â„ tanh (Set.Ioo 0 (Î± * S)) :=
        Activation.differentiable_tanh.differentiableOn
      obtain âŸ¨c, âŸ¨hc_gt, hc_ltâŸ©, h_mvtâŸ© := exists_deriv_eq_slope tanh h1 h_cont h_diff
      rw [tanh_zero, sub_zero, sub_zero] at h_mvt
      have h_deriv_c_lt : deriv tanh c < 1 := by
        rw [Activation.deriv_tanh]
        have h_tanh_c_ne : tanh c â‰  0 := by
          intro heq_c
          have h_c_eq_0 : c = 0 := Activation.tanh_injective (heq_c.trans tanh_zero.symm)
          linarith
        have h_sq_pos : 0 < (tanh c)^2 := sq_pos_of_ne_zero h_tanh_c_ne
        linarith
      have h_ne : Î± * S â‰  0 := ne_of_gt h1
      have h_slope : tanh (Î± * S) = deriv tanh c * (Î± * S) := by
        field_simp at h_mvt
        linarith
      calc tanh (Î± * S) = deriv tanh c * (Î± * S) := h_slope
        _ < 1 * (Î± * S) := mul_lt_mul_of_pos_right h_deriv_c_lt h1
        _ = Î± * S := one_mul _
    have h3 : Î± * S â‰¤ S := by
      -- Î±S â‰¤ S â†” S(Î±-1) â‰¤ 0
      -- S > 0 and Î± - 1 â‰¤ 0, so S(Î±-1) â‰¤ 0
      nlinarith
    -- From h2: tanh(Î±S) < Î±S, and h3: Î±S â‰¤ S
    -- So tanh(Î±S) < S, contradicting hS: tanh(Î±S) = S
    linarith

/-- For Î± > 1, nonzero fixed points exist.
    Key insight: At x = 0, the slope of tanh(Î±x) is Î± > 1 (steeper than y = x).
    Since tanh is bounded by 1, the curve must cross y = x at some x* > 0.
    By odd symmetry, -x* is also a fixed point. -/
theorem nonzero_fixed_point_exists (Î± : â„) (hÎ± : 1 < Î±) :
    âˆƒ S : â„, S â‰  0 âˆ§ isFixedPoint Î± S := by
  -- We use the IVT approach: Define g(x) = tanh(Î±x) - x.
  -- g(0) = 0, g(1) = tanh(Î±) - 1 < 0
  -- Since g'(0) = Î± - 1 > 0, g(Îµ) > 0 for small Îµ > 0.
  -- By IVT, there exists c âˆˆ (Îµ, 1) with g(c) = 0.

  have hÎ±_pos : 0 < Î± := by linarith
  have h_deriv_pos : 0 < Î± - 1 := by linarith

  -- Define g
  let g := fun x => tanh (Î± * x) - x

  -- Helper: x â†¦ Î± * x is differentiable
  have h_mul_diff : Differentiable â„ (fun x => Î± * x) := Differentiable.const_mul differentiable_id Î±

  -- g is differentiable
  have h_g_diff : Differentiable â„ g := by
    intro x
    apply DifferentiableAt.sub
    Â· exact Activation.differentiable_tanh.differentiableAt.comp x (h_mul_diff x)
    Â· exact differentiableAt_id

  -- g'(0) = Î± - 1 > 0
  have h_g_deriv_0 : deriv g 0 = Î± - 1 := by
    -- Compute deriv (tanh âˆ˜ (Î± * Â·)) at 0 using chain rule
    have h_tanh_deriv : HasDerivAt (fun x => tanh (Î± * x)) (Î± * (1 - (tanh (Î± * 0))^2)) 0 := by
      have h1 : HasDerivAt (fun x => Î± * x) Î± 0 := by
        have h1' := (hasDerivAt_id 0).const_mul Î±
        simp only [id, mul_one] at h1'
        exact h1'
      have h2 : HasDerivAt tanh (1 - (tanh (Î± * 0))^2) (Î± * 0) := by
        have hd := Activation.differentiable_tanh.differentiableAt.hasDerivAt (x := Î± * 0)
        rw [Activation.deriv_tanh] at hd
        exact hd
      have h3 := h2.comp 0 h1
      simp only [Function.comp_apply] at h3
      convert h3 using 1
      ring
    simp only [mul_zero, tanh_zero, sq, sub_zero, mul_one] at h_tanh_deriv
    have h1 : deriv (fun x => tanh (Î± * x)) (0 : â„) = Î± := h_tanh_deriv.deriv
    have h2 : deriv (fun x : â„ => x) (0 : â„) = (1 : â„) := by
      have := deriv_id'' (ğ•œ := â„)
      exact congrFun this 0
    have h3 : deriv g (0 : â„) = deriv (fun x => tanh (Î± * x)) 0 - deriv (fun x : â„ => x) 0 := by
      have hdiff1 := Activation.differentiable_tanh.differentiableAt.comp (0 : â„) (h_mul_diff 0)
      have hdiff2 : DifferentiableAt â„ (fun x : â„ => x) (0 : â„) := differentiableAt_id
      exact deriv_sub hdiff1 hdiff2
    rw [h3, h1, h2]

  -- g is C^1, so deriv g is continuous
  have h_deriv_cont : Continuous (deriv g) := by
    -- deriv g x = deriv (tanh âˆ˜ (Î± * Â·)) x - deriv id x = Î± * (1 - tanhÂ²(Î±x)) - 1
    have h_eq : deriv g = fun x => Î± * (1 - (tanh (Î± * x))^2) - 1 := by
      ext y
      -- Compute deriv (tanh âˆ˜ (Î± * Â·)) at y using chain rule
      have h_tanh_deriv : HasDerivAt (fun x => tanh (Î± * x)) (Î± * (1 - (tanh (Î± * y))^2)) y := by
        have h1 : HasDerivAt (fun x => Î± * x) Î± y := by
          have h1' := (hasDerivAt_id y).const_mul Î±
          simp only [id, mul_one] at h1'
          exact h1'
        have h2 : HasDerivAt tanh (1 - (tanh (Î± * y))^2) (Î± * y) := by
          have hd := Activation.differentiable_tanh.differentiableAt.hasDerivAt (x := Î± * y)
          rw [Activation.deriv_tanh] at hd
          exact hd
        have h3 := h2.comp y h1
        simp only [Function.comp_apply] at h3
        convert h3 using 1
        ring
      have h1 : deriv (fun x => tanh (Î± * x)) y = Î± * (1 - (tanh (Î± * y))^2) := h_tanh_deriv.deriv
      have h2 : deriv (fun x : â„ => x) y = (1 : â„) := by
        have := deriv_id'' (ğ•œ := â„)
        exact congrFun this y
      have h3 : deriv g y = deriv (fun x => tanh (Î± * x)) y - deriv (fun x : â„ => x) y := by
        have hdiff1 := Activation.differentiable_tanh.differentiableAt.comp y (h_mul_diff y)
        have hdiff2 : DifferentiableAt â„ (fun x : â„ => x) y := differentiableAt_id
        exact deriv_sub hdiff1 hdiff2
      rw [h3, h1, h2]
    rw [h_eq]
    apply Continuous.sub
    Â· apply Continuous.mul continuous_const
      apply Continuous.sub continuous_const
      apply Continuous.pow
      exact Activation.differentiable_tanh.continuous.comp (continuous_mul_left Î±)
    Â· exact continuous_const

  -- g'(0) = Î± - 1 > 0. By continuity, there exists Î´ > 0 with g'(x) > (Î±-1)/2 for |x| < Î´.
  have h_deriv_cont_at_0 : ContinuousAt (deriv g) 0 := h_deriv_cont.continuousAt
  rw [Metric.continuousAt_iff] at h_deriv_cont_at_0
  obtain âŸ¨Î´, hÎ´_pos, hÎ´_ballâŸ© := h_deriv_cont_at_0 ((Î± - 1)/2) (by linarith)

  -- Choose xâ‚€ = min(Î´/2, 1/2)
  let xâ‚€ := min (Î´/2) (1/2)
  have hxâ‚€_pos : 0 < xâ‚€ := lt_min (half_pos hÎ´_pos) (by norm_num)
  have hxâ‚€_lt_Î´ : xâ‚€ < Î´ := calc xâ‚€ â‰¤ Î´/2 := min_le_left _ _
    _ < Î´ := half_lt_self hÎ´_pos
  have hxâ‚€_lt_one : xâ‚€ < 1 := calc xâ‚€ â‰¤ 1/2 := min_le_right _ _
    _ < 1 := by norm_num

  -- For all c âˆˆ [0, xâ‚€], deriv g c > (Î±-1)/2
  have h_deriv_bound : âˆ€ c âˆˆ Set.Icc 0 xâ‚€, deriv g c > (Î± - 1)/2 := by
    intro c âŸ¨hc_ge, hc_leâŸ©
    have hc_in_ball : dist c 0 < Î´ := by
      rw [dist_zero_right, Real.norm_eq_abs, abs_of_nonneg hc_ge]
      calc c â‰¤ xâ‚€ := hc_le
        _ < Î´ := hxâ‚€_lt_Î´
    have h_dist := hÎ´_ball hc_in_ball
    rw [h_g_deriv_0, dist_eq_norm, Real.norm_eq_abs] at h_dist
    have : |deriv g c - (Î± - 1)| < (Î± - 1) / 2 := h_dist
    have h_abs := abs_lt.mp this
    linarith

  -- By MVT, g(xâ‚€) - g(0) = g'(c) * xâ‚€ for some c âˆˆ (0, xâ‚€)
  have h_mvt_cont : ContinuousOn g (Set.Icc 0 xâ‚€) := h_g_diff.continuous.continuousOn
  have h_mvt_diff : DifferentiableOn â„ g (Set.Ioo 0 xâ‚€) := h_g_diff.differentiableOn
  obtain âŸ¨c, âŸ¨hc_gt, hc_ltâŸ©, h_mvtâŸ© := exists_deriv_eq_slope g hxâ‚€_pos h_mvt_cont h_mvt_diff

  -- g(0) = tanh(0) - 0 = 0
  have h_g0 : g 0 = 0 := by simp [g, tanh_zero]
  rw [h_g0, sub_zero] at h_mvt

  -- g(xâ‚€) = g'(c) * xâ‚€ where g'(c) > (Î±-1)/2
  have hc_in_Icc : c âˆˆ Set.Icc 0 xâ‚€ := âŸ¨le_of_lt hc_gt, le_of_lt hc_ltâŸ©
  have h_gc_bound : deriv g c > (Î± - 1)/2 := h_deriv_bound c hc_in_Icc
  have h_g_x0_pos : g xâ‚€ > 0 := by
    have h_ne : xâ‚€ â‰  0 := ne_of_gt hxâ‚€_pos
    -- h_mvt : deriv g c = g xâ‚€ / (xâ‚€ - 0)
    have h1 : g xâ‚€ = deriv g c * xâ‚€ := by
      simp only [sub_zero] at h_mvt
      field_simp [h_ne] at h_mvt âŠ¢
      linarith
    rw [h1]
    exact mul_pos (by linarith) hxâ‚€_pos

  -- Now we have g(xâ‚€) > 0 and g(1) < 0. By IVT, there exists c âˆˆ (xâ‚€, 1) with g(c) = 0.
  have h_g1_neg : g 1 < 0 := by
    simp only [g]
    -- g 1 = tanh(Î± * 1) - 1 = tanh(Î±) - 1 < 0 since |tanh(Î±)| < 1
    have h_bnd := Activation.tanh_bounded Î±
    have h_lt := abs_lt.mp h_bnd
    have h_mul_one : Î± * 1 = Î± := mul_one Î±
    rw [h_mul_one]
    linarith

  have h_cont : ContinuousOn g (Set.Icc xâ‚€ 1) := h_g_diff.continuous.continuousOn
  have h_le : xâ‚€ â‰¤ 1 := le_of_lt hxâ‚€_lt_one

  have h_ivt := intermediate_value_Icc' h_le h_cont
  have h_zero_in_range : (0 : â„) âˆˆ Set.Icc (g 1) (g xâ‚€) := âŸ¨le_of_lt h_g1_neg, le_of_lt h_g_x0_posâŸ©

  obtain âŸ¨c', âŸ¨hc'_ge, hc'_leâŸ©, hc'_eqâŸ© := h_ivt h_zero_in_range

  use c'
  constructor
  Â· -- c' â‰  0 since c' â‰¥ xâ‚€ > 0
    linarith
  Â· -- isFixedPoint Î± c', i.e., tanh(Î±Â·c') = c'
    simp only [isFixedPoint, tanhRecur, g] at hc'_eq âŠ¢
    linarith

/-- The positive fixed point for Î± > 1 is unique. -/
theorem positive_fixed_point_unique (Î± : â„) (hÎ± : 1 < Î±) :
    âˆ€ Sâ‚ Sâ‚‚ : â„, 0 < Sâ‚ â†’ 0 < Sâ‚‚ â†’ isFixedPoint Î± Sâ‚ â†’ isFixedPoint Î± Sâ‚‚ â†’ Sâ‚ = Sâ‚‚ := by
  intro Sâ‚ Sâ‚‚ h1_pos h2_pos h1_fp h2_fp
  -- Both are roots of f(x) = tanh(Î±x) - x = 0
  -- Key insight: g(x) = tanh(Î±x)/x is strictly decreasing for x > 0.
  -- If tanh(Î±Sâ‚) = Sâ‚ and tanh(Î±Sâ‚‚) = Sâ‚‚, then g(Sâ‚) = 1 = g(Sâ‚‚).
  -- Since g is strictly decreasing, Sâ‚ = Sâ‚‚.
  simp only [isFixedPoint, tanhRecur] at h1_fp h2_fp
  -- h1_fp : tanh(Î± * Sâ‚) = Sâ‚
  -- h2_fp : tanh(Î± * Sâ‚‚) = Sâ‚‚

  -- Proof by contradiction: assume Sâ‚ â‰  Sâ‚‚, WLOG Sâ‚ < Sâ‚‚.
  by_contra h_ne
  wlog h_lt : Sâ‚ < Sâ‚‚ with H
  Â· push_neg at h_lt
    have h_gt : Sâ‚‚ < Sâ‚ := lt_of_le_of_ne h_lt (Ne.symm h_ne)
    exact H Î± hÎ± Sâ‚‚ Sâ‚ h2_pos h1_pos h2_fp h1_fp (Ne.symm h_ne) h_gt

  -- Now we have 0 < Sâ‚ < Sâ‚‚.
  -- tanh(Î±Sâ‚) = Sâ‚ and tanh(Î±Sâ‚‚) = Sâ‚‚
  -- So tanh(Î±Sâ‚)/Sâ‚ = 1 and tanh(Î±Sâ‚‚)/Sâ‚‚ = 1.

  -- Key: For x > 0, let h(x) = tanh(Î±x)/x. We show h is strictly decreasing.
  -- h'(x) = (Î±Â·sechÂ²(Î±x)Â·x - tanh(Î±x)) / xÂ²
  --       = (Î±Â·(1 - tanhÂ²(Î±x))Â·x - tanh(Î±x)) / xÂ²
  -- For h'(x) < 0, need: Î±Â·(1 - tanhÂ²(Î±x))Â·x < tanh(Î±x)
  -- i.e., Î±Â·x < tanh(Î±x) / (1 - tanhÂ²(Î±x)) = tanh(Î±x) Â· coshÂ²(Î±x)
  --     = sinh(Î±x) Â· cosh(Î±x) = sinh(2Î±x)/2
  -- So need: 2Î±x < sinh(2Î±x), which is true for x > 0 (since sinh y > y for y > 0).

  -- Instead of computing h', use the MVT on tanh:
  -- tanh(Î±Sâ‚‚) - tanh(Î±Sâ‚) = Î±Â·(1 - tanhÂ²(Î±c)) Â· (Sâ‚‚ - Sâ‚) for some c âˆˆ (Sâ‚, Sâ‚‚)
  -- Since tanh(Î±Sâ‚‚) = Sâ‚‚ and tanh(Î±Sâ‚) = Sâ‚:
  -- Sâ‚‚ - Sâ‚ = Î±Â·(1 - tanhÂ²(Î±c)) Â· (Sâ‚‚ - Sâ‚)
  -- Since Sâ‚‚ â‰  Sâ‚, divide by Sâ‚‚ - Sâ‚:
  -- 1 = Î±Â·(1 - tanhÂ²(Î±c))
  -- But 1 - tanhÂ²(Î±c) < 1 (since tanh(Î±c) â‰  0 for c > 0), so Î±Â·(1 - tanhÂ²(Î±c)) < Î±.
  -- Since Î± > 1, we need Î±Â·(1 - tanhÂ²(Î±c)) could equal 1 only if (1 - tanhÂ²(Î±c)) = 1/Î± < 1.
  -- Actually this doesn't directly give a contradiction for all Î± > 1.

  -- Better approach: Use strict monotonicity of tanh and the sandwich.
  -- From Sâ‚ < Sâ‚‚ and Î± > 1, we have Î±Sâ‚ < Î±Sâ‚‚.
  -- Since tanh is strictly monotone: tanh(Î±Sâ‚) < tanh(Î±Sâ‚‚), i.e., Sâ‚ < Sâ‚‚. âœ“

  -- But we need to show Sâ‚ = Sâ‚‚, not Sâ‚ < Sâ‚‚. The issue is uniqueness.

  -- Use the fact that x â†¦ tanh(Î±x) - x is strictly decreasing for x > x* where
  -- x* is the fixed point. Actually, let's use the MVT more carefully.

  -- MVT: there exists c âˆˆ (Sâ‚, Sâ‚‚) with
  -- (tanh(Î±Sâ‚‚) - tanh(Î±Sâ‚)) / (Sâ‚‚ - Sâ‚) = deriv tanh (Î±c) Â· Î± = Î±Â·(1 - tanhÂ²(Î±c))
  -- Since tanh(Î±Sâ‚) = Sâ‚ and tanh(Î±Sâ‚‚) = Sâ‚‚:
  -- (Sâ‚‚ - Sâ‚) / (Sâ‚‚ - Sâ‚) = 1 = Î±Â·(1 - tanhÂ²(Î±c))
  -- So 1 - tanhÂ²(Î±c) = 1/Î±.

  have hÎ±_pos : 0 < Î± := by linarith
  have h_Î±S1_pos : 0 < Î± * Sâ‚ := mul_pos hÎ±_pos h1_pos
  have h_Î±S2_pos : 0 < Î± * Sâ‚‚ := mul_pos hÎ±_pos h2_pos
  have h_Î±S_lt : Î± * Sâ‚ < Î± * Sâ‚‚ := mul_lt_mul_of_pos_left h_lt hÎ±_pos

  -- Apply MVT to tanh on [Î±Sâ‚, Î±Sâ‚‚]
  have h_cont : ContinuousOn tanh (Set.Icc (Î± * Sâ‚) (Î± * Sâ‚‚)) :=
    Activation.differentiable_tanh.continuous.continuousOn
  have h_diff : DifferentiableOn â„ tanh (Set.Ioo (Î± * Sâ‚) (Î± * Sâ‚‚)) :=
    Activation.differentiable_tanh.differentiableOn
  obtain âŸ¨c, âŸ¨hc_gt, hc_ltâŸ©, h_mvtâŸ© := exists_deriv_eq_slope tanh h_Î±S_lt h_cont h_diff

  -- h_mvt : deriv tanh c = (tanh(Î±Sâ‚‚) - tanh(Î±Sâ‚)) / (Î±Sâ‚‚ - Î±Sâ‚)
  --                      = (Sâ‚‚ - Sâ‚) / (Î±(Sâ‚‚ - Sâ‚)) = 1/Î±
  have h_slope : (tanh (Î± * Sâ‚‚) - tanh (Î± * Sâ‚)) / (Î± * Sâ‚‚ - Î± * Sâ‚) = 1 / Î± := by
    rw [h1_fp, h2_fp]
    have h_denom : Î± * Sâ‚‚ - Î± * Sâ‚ = Î± * (Sâ‚‚ - Sâ‚) := by ring
    rw [h_denom]
    have h_ne : Sâ‚‚ - Sâ‚ â‰  0 := by linarith
    have hÎ±_ne : Î± â‰  0 := by linarith
    field_simp

  rw [h_slope, Activation.deriv_tanh] at h_mvt
  -- h_mvt : 1 - tanhÂ²(c) = 1/Î±

  have h_c_pos : 0 < c := by linarith
  have h_tanh_c_pos : 0 < tanh c := Activation.tanh_pos_of_pos h_c_pos
  have h_tanh_c_ne : tanh c â‰  0 := ne_of_gt h_tanh_c_pos
  have h_tanh_sq_pos : 0 < (tanh c)^2 := sq_pos_of_ne_zero h_tanh_c_ne

  -- From h_mvt: 1 - tanhÂ²(c) = 1/Î±
  -- So tanhÂ²(c) = 1 - 1/Î± = (Î± - 1)/Î±
  have h_tanh_sq : (tanh c)^2 = (Î± - 1) / Î± := by
    have h1 : 1 - (tanh c)^2 = 1 / Î± := h_mvt
    have hÎ±_ne : Î± â‰  0 := by linarith
    field_simp at h1 âŠ¢
    linarith

  -- Now: (tanh c)Â² = (Î±-1)/Î±.
  -- We have c âˆˆ (Î±Sâ‚, Î±Sâ‚‚).
  -- We also know: Sâ‚ = tanh(Î±Sâ‚), so tanh(Î±Sâ‚) = Sâ‚.
  -- At a fixed point S*, tanh(Î±S*) = S*, so tanhÂ²(Î±S*) = S*Â².

  -- The key contradiction: Let's show that having two distinct positive fixed points
  -- leads to a contradiction with the derivative bound.

  -- Actually, from h_tanh_sq, we know that c is uniquely determined by Î± (up to sign).
  -- Since c > 0, c = tanhâ»Â¹(âˆš((Î±-1)/Î±)) is unique.
  -- But c can be anywhere in (Î±Sâ‚, Î±Sâ‚‚), which is a range.
  -- This doesn't directly give a contradiction.

  -- Alternative: Use that for the fixed point equation tanh(Î±x) = x,
  -- at any positive fixed point x*, deriv of g(x) = tanh(Î±x) - x at x* is
  -- g'(x*) = Î±Â·(1 - tanhÂ²(Î±x*)) - 1 = Î±Â·(1 - x*Â²) - 1 (using tanh(Î±x*) = x*).
  -- From the uniqueness proof in the nonzero_fixed_point_exists theorem,
  -- the fixed point x* satisfies tanh(Î±x*) = x*, so tanhÂ²(Î±x*) = x*Â².
  -- At the fixed point: g'(x*) = Î±(1 - x*Â²) - 1.

  -- For Î± > 1, at the unique fixed point x*, we have Î±(1-x*Â²) = 1 from the MVT.
  -- Wait, that's exactly what we derived: at c, 1 - tanhÂ²(c) = 1/Î±.

  -- The contradiction comes from the fact that there's only one c satisfying this,
  -- but c must be in (Î±Sâ‚, Î±Sâ‚‚) for any pair of fixed points.

  -- Simpler approach: Sâ‚ < Sâ‚‚ but both satisfy tanh(Î±S) = S.
  -- Define f(x) = tanh(Î±x) - x for x > 0.
  -- f(Sâ‚) = 0 = f(Sâ‚‚).
  -- f'(x) = Î±(1 - tanhÂ²(Î±x)) - 1.
  -- At x = 0: f'(0) = Î± - 1 > 0 (so f is increasing near 0).
  -- As x â†’ âˆ: tanh(Î±x) â†’ 1, so f(x) â†’ 1 - x â†’ -âˆ and f'(x) â†’ -1 < 0.
  -- f is continuous, starts at f(0) = 0 with positive derivative,
  -- and goes to -âˆ with negative derivative.
  -- So f has a unique local maximum, crosses 0 exactly once for x > 0.

  -- The formal proof: f is continuous, f(0) = 0, f'(0) > 0, f(x) â†’ -âˆ.
  -- By continuity, f achieves a maximum at some x_max > 0.
  -- For x > x_max, f is strictly decreasing.
  -- Since f(Sâ‚) = 0 = f(Sâ‚‚) and Sâ‚ < Sâ‚‚, both are zeros.
  -- But a function can't have two zeros if it's first increasing then decreasing
  -- (except at the boundaries). Here f(0) = 0 is the starting point.

  -- Let's formalize: f is strictly concave for x > 0 (f'' < 0), so it can cross
  -- y = 0 at most twice total (including x = 0). Since f(0) = 0 and f increases
  -- from 0, there's exactly one other zero.

  -- Actually, we can use Rolle's theorem in reverse:
  -- If f(Sâ‚) = f(Sâ‚‚) = 0 with Sâ‚ < Sâ‚‚, then there exists c âˆˆ (Sâ‚, Sâ‚‚) with f'(c) = 0.
  -- f'(c) = 0 means Î±(1 - tanhÂ²(Î±c)) = 1, i.e., tanhÂ²(Î±c) = (Î±-1)/Î±.
  -- This gives a unique c > 0 (since tanh is strictly monotone).
  -- But Sâ‚ and Sâ‚‚ are both > 0, and the MVT c is unique.

  -- Wait, from h_mvt we have: 1 - tanhÂ²(c) = 1/Î± where c âˆˆ (Î±Sâ‚, Î±Sâ‚‚).
  -- This means the slope of the secant line from (Î±Sâ‚, Sâ‚) to (Î±Sâ‚‚, Sâ‚‚) on the
  -- tanh curve equals the derivative at c, which is 1/Î±.

  -- But the secant has slope (Sâ‚‚ - Sâ‚)/(Î±Sâ‚‚ - Î±Sâ‚) = 1/Î±.
  -- And points (Î±Sâ‚, Sâ‚), (Î±Sâ‚‚, Sâ‚‚) are ON the line y = x/Î± (since S = tanh(Î±S)).

  -- Actually, the fixed points satisfy tanh(Î±S) = S, which means on the
  -- curve y = tanh(x), the points (Î±Sâ‚, Sâ‚) and (Î±Sâ‚‚, Sâ‚‚) lie on y = x/Î±.

  -- Since tanh is strictly concave for x > 0 (tanh'' < 0), the curve y = tanh(x)
  -- lies below any secant line for x > 0. But if two points on tanh also lie
  -- on y = x/Î±, the secant between them has slope 1/Î±...

  -- This is getting complicated. Let me use a direct monotonicity argument.

  -- Key insight: Let h(x) = tanh(Î±x) - x for x > 0.
  -- h(0) = 0, h'(0) = Î± - 1 > 0.
  -- h''(x) = -2Î±Â²Â·tanh(Î±x)Â·(1 - tanhÂ²(Î±x)) < 0 for x > 0 (since tanh(Î±x) > 0).
  -- So h is strictly concave for x > 0.
  -- A strictly concave function with h(0) = 0 and h'(0) > 0 can have at most one
  -- zero for x > 0.

  -- To show: h can't have two zeros Sâ‚ < Sâ‚‚ with both > 0.
  -- Proof: h(Sâ‚) = h(Sâ‚‚) = 0. By Rolle's theorem, âˆƒ c âˆˆ (Sâ‚, Sâ‚‚) with h'(c) = 0.
  -- h'(c) = Î±(1 - tanhÂ²(Î±c)) - 1 = 0 means 1 - tanhÂ²(Î±c) = 1/Î±.
  -- So c satisfies this equation uniquely (tanh is strictly monotone).

  -- But also: h is strictly concave, h(0) = 0, h'(0) > 0.
  -- So h increases on [0, c_max] and decreases on [c_max, âˆ) for some c_max > 0.
  -- The unique zero of h' for x > 0 is c_max (where h'(c_max) = 0).

  -- For Sâ‚ > 0 with h(Sâ‚) = 0: either Sâ‚ â‰¤ c_max or Sâ‚ > c_max.
  -- If Sâ‚ â‰¤ c_max: h goes from h(0) = 0, increases to h(c_max) > 0, then decreases.
  --   For h(Sâ‚) = 0 with 0 < Sâ‚ â‰¤ c_max, and h increasing on [0, c_max],
  --   this would mean h(Sâ‚) > h(0) = 0, contradiction.
  -- So Sâ‚ > c_max, meaning Sâ‚ is on the decreasing part.
  -- Similarly Sâ‚‚ > c_max.
  -- Since h is strictly decreasing on (c_max, âˆ) and h(Sâ‚) = h(Sâ‚‚) = 0,
  -- we must have Sâ‚ = Sâ‚‚.

  -- Let me find the unique c_max where h'(c_max) = 0.
  -- h'(x) = Î±(1 - tanhÂ²(Î±x)) - 1 = 0
  -- 1 - tanhÂ²(Î±x) = 1/Î±
  -- tanhÂ²(Î±x) = (Î± - 1)/Î±

  -- Since tanh is strictly increasing and positive for positive args,
  -- tanh(Î±x) = âˆš((Î±-1)/Î±) has a unique solution x = x_max > 0.

  -- Now, the fixed point equation tanh(Î±S) = S gives S = tanh(Î±S).
  -- At S_max where h'(S_max) = 0:
  -- tanhÂ²(Î±S_max) = (Î±-1)/Î±
  -- tanh(Î±S_max) = âˆš((Î±-1)/Î±) (positive root since S_max > 0)
  -- If S_max is a fixed point: S_max = tanh(Î±S_max) = âˆš((Î±-1)/Î±)
  -- Then h(S_max) = tanh(Î±S_max) - S_max = S_max - S_max = 0!
  -- So S_max itself is the fixed point!

  -- This means: the unique fixed point S* > 0 is exactly where h'(S*) = 0.
  -- But then h(S*) = 0 and h'(S*) = 0.
  -- For x < S*: h'(x) > 0 (h is increasing)
  -- For x > S*: h'(x) < 0 (h is decreasing)
  -- And h(0) = 0, h(S*) = 0, with h increasing on (0, S*).
  -- This means h(x) > 0 for x âˆˆ (0, S*).
  -- For x > S*: h decreases from h(S*) = 0, so h(x) < 0.
  -- Therefore, the only zeros of h for x > 0 are... wait, h(x) > 0 on (0, S*)
  -- and h(x) < 0 on (S*, âˆ). So S* is the only zero!

  -- But we assumed h(Sâ‚) = h(Sâ‚‚) = 0 with 0 < Sâ‚ < Sâ‚‚. Contradiction!

  -- Let me formalize this by showing h(x) > 0 on (0, S*) using MVT.
  -- Actually, the argument that S* is the critical point simplifies things.

  -- From h(Sâ‚) = 0 and Sâ‚ > 0, and the analysis above, Sâ‚ must equal S*.
  -- Similarly Sâ‚‚ = S*. Hence Sâ‚ = Sâ‚‚.

  -- The formal contradiction: We have Sâ‚ < Sâ‚‚, but by Rolle's theorem on [Sâ‚, Sâ‚‚],
  -- there exists c âˆˆ (Sâ‚, Sâ‚‚) with h'(c) = 0. But we showed the unique critical
  -- point x_max satisfies h(x_max) = 0. So c = x_max = S* is the unique fixed point.
  -- But c âˆˆ (Sâ‚, Sâ‚‚) and Sâ‚, Sâ‚‚ are both fixed points (h(Sâ‚) = h(Sâ‚‚) = 0).
  -- So Sâ‚ < c < Sâ‚‚ and c is also a zero of h. But Sâ‚, c, Sâ‚‚ are three distinct
  -- zeros of h for x > 0... no wait, we have Sâ‚ < Sâ‚‚ but c âˆˆ (Sâ‚, Sâ‚‚), and we're
  -- saying h(Sâ‚) = h(c) = h(Sâ‚‚) = 0? That's three zeros!

  -- Actually, by Rolle's theorem applied to h on [Sâ‚, Sâ‚‚]:
  -- h(Sâ‚) = h(Sâ‚‚) = 0 implies âˆƒ c âˆˆ (Sâ‚, Sâ‚‚) with h'(c) = 0.
  -- h'(c) = 0 means c is a critical point of h.
  -- But h is strictly concave (h'' < 0), so h has at most one critical point.
  -- And we showed that at the unique critical point c*, h(c*) = 0.

  -- So c = c* (unique critical point). And h(c*) = 0.
  -- But c âˆˆ (Sâ‚, Sâ‚‚), so Sâ‚ < c* < Sâ‚‚.
  -- And h(Sâ‚) = h(c*) = h(Sâ‚‚) = 0.

  -- Now: h is strictly increasing on (0, c*) (since h' > 0 there).
  -- h(0) = 0 and h is strictly increasing, so h(x) > 0 for x âˆˆ (0, c*).
  -- But Sâ‚ âˆˆ (0, c*) (since 0 < Sâ‚ < c*), so h(Sâ‚) > 0. Contradiction!

  -- So the assumption Sâ‚ < Sâ‚‚ leads to h(Sâ‚) > 0, contradicting h(Sâ‚) = 0.

  -- Formally:
  -- By Rolle on [Sâ‚, Sâ‚‚]: âˆƒ c âˆˆ (Sâ‚, Sâ‚‚) with h'(c) = 0.
  -- Let h(x) = tanh(Î±x) - x for the following.

  -- h'(x) = Î±Â·(1 - tanhÂ²(Î±x)) - 1
  -- h'(c) = 0 means Î±Â·(1 - tanhÂ²(Î±c)) = 1, i.e., 1 - tanhÂ²(Î±c) = 1/Î±.

  -- h is increasing on (0, c) (where h' > 0) and h(0) = 0.
  -- So for 0 < Sâ‚ < c: h(Sâ‚) > h(0) = 0. But h(Sâ‚) = 0 is given. Contradiction!

  -- Let's implement this.

  -- Define h(x) = tanh(Î±x) - x
  let h := fun x => tanh (Î± * x) - x

  have h_S1 : h Sâ‚ = 0 := by simp only [h]; linarith [h1_fp]
  have h_S2 : h Sâ‚‚ = 0 := by simp only [h]; linarith [h2_fp]

  -- By Rolle's theorem, âˆƒ c âˆˆ (Sâ‚, Sâ‚‚) with h'(c) = 0.
  have h_cont_h : ContinuousOn h (Set.Icc Sâ‚ Sâ‚‚) := by
    apply ContinuousOn.sub
    Â· exact (Activation.differentiable_tanh.continuous.comp (continuous_mul_left Î±)).continuousOn
    Â· exact continuous_id.continuousOn
  have h_diff_h : DifferentiableOn â„ h (Set.Ioo Sâ‚ Sâ‚‚) := by
    apply DifferentiableOn.sub
    Â· exact (Activation.differentiable_tanh.comp
        (Differentiable.const_mul differentiable_id Î±)).differentiableOn
    Â· exact differentiable_id.differentiableOn

  have h_S1_le_S2 : Sâ‚ â‰¤ Sâ‚‚ := le_of_lt h_lt
  have h_eq_ends : h Sâ‚ = h Sâ‚‚ := by rw [h_S1, h_S2]

  obtain âŸ¨c_rolle, âŸ¨hc_gt, hc_ltâŸ©, h_rolleâŸ© :=
    exists_deriv_eq_slope h h_lt h_cont_h h_diff_h
  -- h_rolle : deriv h c_rolle = (h Sâ‚‚ - h Sâ‚) / (Sâ‚‚ - Sâ‚)

  have h_deriv_h : âˆ€ x, deriv h x = Î± * (1 - (tanh (Î± * x))^2) - 1 := by
    intro x
    have hd : HasDerivAt h (Î± * (1 - (tanh (Î± * x))^2) - 1) x := by
      have h1 : HasDerivAt (fun y => Î± * y) Î± x := by
        have h1' := (hasDerivAt_id x).const_mul Î±
        simp only [id, mul_one] at h1'
        exact h1'
      have h2 : HasDerivAt tanh (1 - (tanh (Î± * x))^2) (Î± * x) := by
        have hd := Activation.differentiable_tanh.differentiableAt.hasDerivAt (x := Î± * x)
        rw [Activation.deriv_tanh] at hd
        exact hd
      have h3 := h2.comp x h1
      simp only [Function.comp_apply] at h3
      -- h3 gives derivative = (1 - tanhÂ²(Î±x)) * Î±
      have h5 : HasDerivAt (fun y => tanh (Î± * y)) (Î± * (1 - (tanh (Î± * x))^2)) x := by
        convert h3 using 1
        ring
      have h6 : HasDerivAt (fun y : â„ => y) 1 x := hasDerivAt_id x
      have h7 := h5.sub h6
      simp only [h] at h7 âŠ¢
      convert h7 using 1
    exact hd.deriv

  have h_deriv_at_c : deriv h c_rolle = 0 := by
    rw [h_rolle, h_S1, h_S2, sub_self, zero_div]

  rw [h_deriv_h] at h_deriv_at_c
  -- h_deriv_at_c : Î± * (1 - tanhÂ²(Î±c_rolle)) - 1 = 0
  -- So: 1 - tanhÂ²(Î±c_rolle) = 1/Î±

  have h_c_pos : 0 < c_rolle := by linarith
  have h_Î±c_pos : 0 < Î± * c_rolle := mul_pos hÎ±_pos h_c_pos

  -- Now: h is strictly increasing on (0, c_rolle).
  -- Proof: For x âˆˆ (0, c_rolle), h'(x) > 0.
  -- h'(x) = Î±(1 - tanhÂ²(Î±x)) - 1
  -- We need Î±(1 - tanhÂ²(Î±x)) > 1, i.e., 1 - tanhÂ²(Î±x) > 1/Î±.

  -- At c_rolle: 1 - tanhÂ²(Î±c_rolle) = 1/Î±.
  -- For x < c_rolle: Î±x < Î±c_rolle, so tanh(Î±x) < tanh(Î±c_rolle) (tanh increasing).
  -- So tanhÂ²(Î±x) < tanhÂ²(Î±c_rolle), hence 1 - tanhÂ²(Î±x) > 1 - tanhÂ²(Î±c_rolle) = 1/Î±.
  -- Therefore h'(x) = Î±(1 - tanhÂ²(Î±x)) - 1 > Î± Â· (1/Î±) - 1 = 0.

  have h_deriv_pos_on_0_c : âˆ€ x, 0 < x â†’ x < c_rolle â†’ deriv h x > 0 := by
    intro x hx_pos hx_lt
    rw [h_deriv_h]
    have h_Î±x_pos : 0 < Î± * x := mul_pos hÎ±_pos hx_pos
    have h_Î±x_lt : Î± * x < Î± * c_rolle := mul_lt_mul_of_pos_left hx_lt hÎ±_pos
    have h_tanh_mono : tanh (Î± * x) < tanh (Î± * c_rolle) :=
      Activation.tanh_strictMono h_Î±x_lt
    have h_tanh_x_pos : 0 < tanh (Î± * x) := Activation.tanh_pos_of_pos h_Î±x_pos
    have h_tanh_c_pos : 0 < tanh (Î± * c_rolle) := Activation.tanh_pos_of_pos h_Î±c_pos
    have h_sq_mono : (tanh (Î± * x))^2 < (tanh (Î± * c_rolle))^2 :=
      sq_lt_sq' (by linarith) h_tanh_mono
    -- 1 - tanhÂ²(Î±x) > 1 - tanhÂ²(Î±c_rolle) = 1/Î±
    have h_one_minus : 1 - (tanh (Î± * x))^2 > 1 - (tanh (Î± * c_rolle))^2 := by linarith
    have h_eq_inv : 1 - (tanh (Î± * c_rolle))^2 = 1 / Î± := by
      have : Î± * (1 - (tanh (Î± * c_rolle))^2) - 1 = 0 := h_deriv_at_c
      have hÎ±_ne : Î± â‰  0 := by linarith
      field_simp at this âŠ¢
      linarith
    rw [h_eq_inv] at h_one_minus
    -- h'(x) = Î±(1 - tanhÂ²(Î±x)) - 1 > Î± Â· (1/Î±) - 1 = 0
    have hÎ±_ne : Î± â‰  0 := by linarith
    have h_one_over : Î± * (1 / Î±) = 1 := by field_simp
    calc Î± * (1 - (tanh (Î± * x))^2) - 1 > Î± * (1 / Î±) - 1 := by nlinarith [hÎ±_pos]
      _ = 1 - 1 := by rw [h_one_over]
      _ = 0 := by ring

  -- h(0) = tanh(0) - 0 = 0
  have h_at_0 : h 0 = 0 := by simp [h, tanh_zero]

  -- For Sâ‚ âˆˆ (0, c_rolle): h(Sâ‚) > h(0) = 0 by strict monotonicity.
  have h_S1_lt_c : Sâ‚ < c_rolle := hc_gt

  -- Use MVT on [0, Sâ‚]: h(Sâ‚) - h(0) = h'(Î¾) Â· Sâ‚ for some Î¾ âˆˆ (0, Sâ‚)
  have h_S1_ge_0 : 0 â‰¤ Sâ‚ := le_of_lt h1_pos
  -- Actually we need [0, Sâ‚], not a subset of [Sâ‚, Sâ‚‚].
  have h_cont_0S1 : ContinuousOn h (Set.Icc 0 Sâ‚) := by
    apply ContinuousOn.sub
    Â· exact (Activation.differentiable_tanh.continuous.comp (continuous_mul_left Î±)).continuousOn
    Â· exact continuous_id.continuousOn
  have h_diff_0S1 : DifferentiableOn â„ h (Set.Ioo 0 Sâ‚) := by
    apply DifferentiableOn.sub
    Â· exact (Activation.differentiable_tanh.comp
        (Differentiable.const_mul differentiable_id Î±)).differentiableOn
    Â· exact differentiable_id.differentiableOn

  obtain âŸ¨Î¾, âŸ¨hÎ¾_gt, hÎ¾_ltâŸ©, h_mvt_xiâŸ© :=
    exists_deriv_eq_slope h h1_pos h_cont_0S1 h_diff_0S1

  -- h_mvt_xi : deriv h Î¾ = (h Sâ‚ - h 0) / (Sâ‚ - 0) = h(Sâ‚) / Sâ‚
  have h_deriv_xi_eq : deriv h Î¾ = h Sâ‚ / Sâ‚ := by
    rw [h_at_0, sub_zero, sub_zero] at h_mvt_xi
    exact h_mvt_xi

  -- Î¾ âˆˆ (0, Sâ‚) âŠ‚ (0, c_rolle), so h'(Î¾) > 0.
  have hÎ¾_lt_c : Î¾ < c_rolle := by linarith

  have h_deriv_xi_pos : deriv h Î¾ > 0 := h_deriv_pos_on_0_c Î¾ hÎ¾_gt hÎ¾_lt_c

  -- h(Sâ‚) / Sâ‚ = h'(Î¾) > 0, and Sâ‚ > 0, so h(Sâ‚) > 0.
  have h_S1_pos : h Sâ‚ > 0 := by
    rw [h_deriv_xi_eq] at h_deriv_xi_pos
    have h_S1_pos' : 0 < Sâ‚ := h1_pos
    exact (div_pos_iff_of_pos_right h_S1_pos').mp h_deriv_xi_pos

  -- But h(Sâ‚) = 0 by h_S1. Contradiction!
  linarith

/-! ## Part 3: Stability of Fixed Points -/

/-- The derivative of tanhRecur: d/dS[tanh(Î±S)] = Î±Â·(1 - tanhÂ²(Î±S)). -/
theorem tanhRecur_deriv (Î± S : â„) :
    deriv (tanhRecur Î±) S = Î± * (1 - (tanh (Î± * S))^2) := by
  -- d/dS[tanh(Î±S)] = tanh'(Î±S) Â· Î± = (1 - tanhÂ²(Î±S)) Â· Î±
  -- By chain rule: deriv (f âˆ˜ g) = (deriv f âˆ˜ g) * deriv g
  unfold tanhRecur
  have h : HasDerivAt (fun x => tanh (Î± * x)) (Î± * (1 - (tanh (Î± * S))^2)) S := by
    have h1 : HasDerivAt (fun x => Î± * x) Î± S := by
      have h1' := (hasDerivAt_id S).const_mul Î±
      simp only [id, mul_one] at h1'
      exact h1'
    have h2 : HasDerivAt tanh (1 - (tanh (Î± * S))^2) (Î± * S) := by
      have hd := Activation.differentiable_tanh.differentiableAt.hasDerivAt (x := Î± * S)
      rw [Activation.deriv_tanh] at hd
      exact hd
    have h3 := h2.comp S h1
    simp only [Function.comp_apply] at h3
    convert h3 using 1
    ring
  exact h.deriv

/-- At a fixed point S* with |S*| close to 1, the derivative is small.
    This makes the fixed point stable (an attractor). -/
theorem fixed_point_stability (Î± : â„) (hÎ± : 0 < Î±) (hÎ±_le : Î± â‰¤ 2) (S : â„)
    (hfp : isFixedPoint Î± S) (hS : |S| > 0.9) :
    |deriv (tanhRecur Î±) S| < 1 := by
  rw [tanhRecur_deriv]
  simp only [isFixedPoint, tanhRecur] at hfp
  rw [hfp]  -- Replace tanh(Î±S) with S
  -- |Î± Â· (1 - SÂ²)| < 1
  -- Since |S| > 0.9, SÂ² > 0.81, so 1 - SÂ² < 0.19
  -- Î± Â· (1 - SÂ²) < 2 Â· 0.19 = 0.38 < 1
  have h_S_sq : (0.9 : â„)^2 < S^2 := by
    have h1 : (0.9 : â„) < |S| := hS
    have h2 : (0.9 : â„)^2 < |S|^2 := sq_lt_sq' (by linarith) h1
    rwa [sq_abs] at h2
  have h_one_minus_sq : 1 - S^2 < 1 - 0.81 := by
    have : (0.9 : â„)^2 = 0.81 := by norm_num
    linarith
  have h_bound : 1 - S^2 < 0.19 := by linarith
  have h_nonneg : 0 â‰¤ 1 - S^2 := by
    have h_bnd := Activation.tanh_bounded (Î± * S)
    rw [hfp] at h_bnd
    rw [abs_lt] at h_bnd
    have h_sq : S^2 < 1 := by nlinarith
    linarith
  rw [abs_mul, abs_of_pos hÎ±, abs_of_nonneg h_nonneg]
  calc Î± * (1 - S^2) < Î± * 0.19 := mul_lt_mul_of_pos_left h_bound hÎ±
    _ â‰¤ 2 * 0.19 := mul_le_mul_of_nonneg_right hÎ±_le (by linarith)
    _ = 0.38 := by norm_num
    _ < 1 := by norm_num

/-! ## Part 4: Alert State Definition and Properties -/

/-- tanh(1) > 0.76. This is used for proving alert state persistence. -/
theorem tanh_one_gt_076 : tanh 1 > 0.76 := by
  -- tanh(1) = (e - eâ»Â¹)/(e + eâ»Â¹) â‰ˆ 0.7616
  -- We prove by showing 19(e + eâ»Â¹) < 25(e - eâ»Â¹), i.e., 44/e < 6e, i.e., eÂ² > 22/3
  -- Since e > 2.718, eÂ² > 7.38 > 7.33. âœ“
  have he_pos : exp 1 > 0 := exp_pos 1
  have he_ge : exp 1 > 2.718 := by
    exact lt_trans (by norm_num : (2.718 : â„) < 2.7182818283) Real.exp_one_gt_d9
  have he_sq : exp 1 * exp 1 > 7.38 := by nlinarith
  have hei_eq : exp (-1) = (exp 1)â»Â¹ := Real.exp_neg 1
  have hei_pos : 0 < (exp 1)â»Â¹ := inv_pos.mpr he_pos
  have hne : exp 1 â‰  0 := he_pos.ne'
  -- Transform tanh(1) to (e - eâ»Â¹)/(e + eâ»Â¹)
  rw [Real.tanh_eq_sinh_div_cosh, Real.sinh_eq, Real.cosh_eq, hei_eq]
  -- Simplify (e - eâ»Â¹)/2 / ((e + eâ»Â¹)/2) to (e - eâ»Â¹)/(e + eâ»Â¹)
  have hsum_pos : 0 < exp 1 + (exp 1)â»Â¹ := by linarith
  have h_eq : (exp 1 - (exp 1)â»Â¹) / 2 / ((exp 1 + (exp 1)â»Â¹) / 2) =
              (exp 1 - (exp 1)â»Â¹) / (exp 1 + (exp 1)â»Â¹) := by field_simp
  rw [h_eq]
  -- Need (e - eâ»Â¹)/(e + eâ»Â¹) > 19/25
  rw [gt_iff_lt, lt_div_iffâ‚€ hsum_pos]
  -- Need 0.76 * (e + eâ»Â¹) < e - eâ»Â¹
  -- i.e., 19/25 * (e + eâ»Â¹) < e - eâ»Â¹
  -- i.e., 19(e + eâ»Â¹) < 25(e - eâ»Â¹)
  -- i.e., 19e + 19/e < 25e - 25/e
  -- i.e., 44/e < 6e
  -- i.e., 44 < 6eÂ²
  have h1 : (0.76 : â„) * (exp 1 + (exp 1)â»Â¹) < exp 1 - (exp 1)â»Â¹ := by
    have h2 : (exp 1)â»Â¹ < 0.37 := by
      rw [inv_lt_commâ‚€ he_pos (by norm_num : (0 : â„) < 0.37)]
      calc (0.37 : â„)â»Â¹ < 2.71 := by norm_num
        _ < exp 1 := lt_trans (by norm_num) he_ge
    nlinarith
  exact h1

/-- For x â‰¥ 1, tanh(x) > 0.76. -/
theorem tanh_gt_076_of_ge_one (x : â„) (hx : 1 â‰¤ x) : tanh x > 0.76 := by
  calc tanh x â‰¥ tanh 1 := Activation.tanh_strictMono.monotone hx
    _ > 0.76 := tanh_one_gt_076

/-- exp(2.2) > 9. This is used for proving tanh(1.1) > 0.8.
    Numerical verification: exp(2.2) â‰ˆ 9.025 > 9. -/
theorem exp_2_2_gt_9 : exp 2.2 > 9 := by
  -- e^2.2 = e^2 * e^0.2 â‰ˆ 7.389 * 1.221 â‰ˆ 9.025 > 9
  -- Using quadratic_le_exp_of_nonneg: 1 + x + xÂ²/2 â‰¤ exp x for x â‰¥ 0
  have h_exp22 : exp 2.2 = exp 2 * exp 0.2 := by rw [â† Real.exp_add]; norm_num
  -- Tight bound on exp 2 using Mathlib's exp_one_gt_d9: exp 1 > 2.7182818283
  have h_exp2 : exp 2 > 7.389 := by
    have h2a : exp 2 = exp 1 * exp 1 := by rw [â† Real.exp_add]; norm_num
    calc exp 2 = exp 1 * exp 1 := h2a
      _ > 2.7182818283 * 2.7182818283 := by nlinarith [Real.exp_one_gt_d9, exp_pos 1]
      _ > 7.389 := by norm_num
  -- For exp 0.2, use quadratic Taylor bound: exp x â‰¥ 1 + x + xÂ²/2
  have h_exp02 : exp 0.2 â‰¥ 1.22 := by
    have h := quadratic_le_exp_of_nonneg (by norm_num : (0 : â„) â‰¤ 0.2)
    calc exp 0.2 â‰¥ 1 + 0.2 + (0.2 : â„)^2 / 2 := h
      _ = 1.22 := by norm_num
  -- 7.389 * 1.22 = 9.01458 > 9
  calc exp 2.2 = exp 2 * exp 0.2 := h_exp22
    _ > 7.389 * 1.22 := by nlinarith [exp_pos 2, exp_pos 0.2, h_exp2, h_exp02]
    _ > 9 := by norm_num

/-- tanh(1.1) > 0.8. This is the key numerical bound for alert state persistence.
    Numerical verification: tanh(1.1) â‰ˆ 0.8005 > 0.8. -/
theorem tanh_11_gt_08 : tanh 1.1 > 0.8 := by
  -- tanh(x) = (e^2x - 1)/(e^2x + 1)
  -- For tanh(x) > c, we need e^2x > (1+c)/(1-c)
  -- For tanh(1.1) > 0.8, we need e^2.2 > 1.8/0.2 = 9
  rw [Real.tanh_eq_sinh_div_cosh, Real.sinh_eq, Real.cosh_eq]
  have h_exp22 : exp 2.2 > 9 := exp_2_2_gt_9
  have h_exp11_pos : exp 1.1 > 0 := exp_pos 1.1
  have h_exp_neg11 : exp (-1.1) = (exp 1.1)â»Â¹ := Real.exp_neg 1.1
  have h_inv_pos : 0 < (exp 1.1)â»Â¹ := inv_pos.mpr h_exp11_pos
  -- sinh(1.1)/cosh(1.1) = (e^1.1 - e^-1.1)/(e^1.1 + e^-1.1) = (e^2.2 - 1)/(e^2.2 + 1)
  have h_simp : (exp 1.1 - (exp 1.1)â»Â¹) / 2 / ((exp 1.1 + (exp 1.1)â»Â¹) / 2) =
                (exp 2.2 - 1) / (exp 2.2 + 1) := by
    have h_sq : exp 1.1 * exp 1.1 = exp 2.2 := by rw [â† Real.exp_add]; norm_num
    have hne : exp 1.1 â‰  0 := h_exp11_pos.ne'
    field_simp
    rw [â† h_sq]
    ring
  rw [h_exp_neg11, h_simp]
  -- (exp 2.2 - 1)/(exp 2.2 + 1) > 0.8 iff exp 2.2 > (1+0.8)/(1-0.8) = 9
  have h_denom_pos : exp 2.2 + 1 > 0 := by linarith [exp_pos 2.2]
  -- Need (exp 2.2 - 1)/(exp 2.2 + 1) > 0.8 = 4/5
  -- Rearranging: 5(exp 2.2 - 1) > 4(exp 2.2 + 1)
  -- 5 exp 2.2 - 5 > 4 exp 2.2 + 4
  -- exp 2.2 > 9
  rw [gt_iff_lt, lt_div_iffâ‚€ h_denom_pos]
  -- Goal: 0.8 * (exp 2.2 + 1) < exp 2.2 - 1
  linarith

/-- For x â‰¥ 1.1, tanh(x) > 0.8. -/
theorem tanh_gt_08_of_ge_11 (x : â„) (hx : 1.1 â‰¤ x) : tanh x > 0.8 := by
  calc tanh x â‰¥ tanh 1.1 := Activation.tanh_strictMono.monotone hx
    _ > 0.8 := tanh_11_gt_08

/-- An "alert" state is one where |S| exceeds a threshold Î¸.
    This represents a head that has detected a pattern and "latched" onto it. -/
def isAlert (S Î¸ : â„) : Prop := Î¸ < |S|

/-- The alert basin: states that remain alert under iteration.
    A state S is in the alert basin if tanhRecurIter Î± n S is alert for all n. -/
def alertBasin (Î± Î¸ : â„) : Set â„ :=
  {S | âˆ€ n : â„•, isAlert (tanhRecurIter Î± n S) Î¸}

/-- For appropriate Î¸, the alert basin is non-empty.
    Key: For Î± > 1, the positive fixed point S* has |S*| close to 1.
    Any state |S| â‰¥ |S*| will converge to S* and stay in the alert region.

    CRITICAL CONSTRAINT: We require Î¸ < tanh(Î± * Î¸), which ensures Î¸ is below the
    fixed point S*(Î±). Without this, the theorem is false for Î± close to 1 and Î¸ close to 1.
    E.g., for Î± = 1.01 and Î¸ = 0.99, the fixed point S* â‰ˆ 0.1 < Î¸. -/
theorem alert_basin_nonempty (Î± Î¸ : â„) (hÎ± : 1 < Î±) (hÎ¸_pos : 0 < Î¸) (hÎ¸_lt : Î¸ < 1)
    (hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸)) :
    âˆƒ S : â„, S âˆˆ alertBasin Î± Î¸ := by
  -- With Î¸ < tanh(Î± * Î¸), we know Î¸ is below the fixed point S*.
  -- Starting at Sâ‚€ = 1, all iterations stay above Î¸.
  use 1
  intro n
  simp only [isAlert]
  have h_Î±_pos : 0 < Î± := lt_trans zero_lt_one hÎ±
  -- All iterates starting from 1 are positive
  have h_iter_pos : âˆ€ m, 0 < tanhRecurIter Î± m 1 := by
    intro m
    induction m with
    | zero => simp only [tanhRecurIter]; norm_num
    | succ k ih =>
      simp only [tanhRecurIter, tanhRecur]
      exact Activation.tanh_pos_of_pos (mul_pos h_Î±_pos ih)
  -- Key lemma: For x > Î¸, we have tanh(Î±*x) > tanh(Î±*Î¸) > Î¸.
  -- So the property iter > Î¸ is preserved by the iteration.
  -- First prove the inequality without abs, then wrap in abs
  have h_gt : tanhRecurIter Î± n 1 > Î¸ := by
    induction n with
    | zero =>
      simp only [tanhRecurIter]
      exact hÎ¸_lt
    | succ m ih =>
      simp only [tanhRecurIter, tanhRecur]
      have h_prev_pos := h_iter_pos m
      -- Since iter_m > Î¸ > 0 and Î± > 0, we have Î± * iter_m > Î± * Î¸
      have h_arg_gt : Î± * tanhRecurIter Î± m 1 > Î± * Î¸ :=
        mul_lt_mul_of_pos_left ih h_Î±_pos
      -- By strict monotonicity of tanh:
      have h_result : tanh (Î± * tanhRecurIter Î± m 1) > tanh (Î± * Î¸) :=
        Activation.tanh_strictMono h_arg_gt
      -- And by hypothesis, tanh(Î± * Î¸) > Î¸
      linarith
  rw [abs_of_pos (h_iter_pos n)]
  exact h_gt

/-- Forward invariance: if |S| > Î¸ and Î¸ is chosen appropriately,
    then |tanhRecur Î± S| > Î¸. This means alert states stay alert.

    CRITICAL CONSTRAINT: We require Î¸ < tanh(Î± * Î¸), which ensures Î¸ is below the
    fixed point. This is the key condition for alert states to persist. -/
theorem alert_forward_invariant (Î± Î¸ : â„) (hÎ± : 1 < Î±) (hÎ¸_pos : 0 < Î¸) (hÎ¸_lt : Î¸ < 0.8)
    (hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸))
    (S : â„) (hS : isAlert S Î¸) :
    isAlert (tanhRecur Î± S) Î¸ := by
  simp only [isAlert] at hS âŠ¢
  simp only [tanhRecur]
  -- Need: Î¸ < |tanh(Î±S)| given Î¸ < |S|
  -- Key insight: |tanh(Î±S)| = tanh(|Î±S|) = tanh(Î±|S|) by oddness of tanh
  -- We have Î±|S| > Î±Î¸ > Î¸ (since Î± > 1)
  -- Strategy: show tanh(Î±|S|) > Î¸ using monotonicity and the bound Î¸ < 0.8
  have hÎ±_pos : 0 < Î± := by linarith
  have h_abs_S_pos : 0 < |S| := lt_of_lt_of_le hÎ¸_pos (le_of_lt hS)
  have h_S_ne_zero : S â‰  0 := fun h => by simp [h] at hS; linarith
  have h_Î±S_bound : Î± * Î¸ < Î± * |S| := mul_lt_mul_of_pos_left hS hÎ±_pos
  have h_Î±Î¸_gt_Î¸ : Î¸ < Î± * Î¸ := by
    have : 1 < Î± := hÎ±
    have : 1 * Î¸ < Î± * Î¸ := mul_lt_mul_of_pos_right this hÎ¸_pos
    linarith
  have h_Î±_abs_S_gt_Î¸ : Î¸ < Î± * |S| := lt_trans h_Î±Î¸_gt_Î¸ h_Î±S_bound
  -- |tanh(Î±S)| = tanh(Î±|S|) by tanh being odd
  have h_tanh_abs : |tanh (Î± * S)| = tanh (Î± * |S|) := by
    by_cases hS_pos : 0 < S
    Â· rw [abs_of_pos hS_pos]
      have h_Î±S_pos : 0 < Î± * S := mul_pos hÎ±_pos hS_pos
      rw [abs_of_pos (Activation.tanh_pos_of_pos h_Î±S_pos)]
    Â· push_neg at hS_pos
      have hS_neg : S < 0 := lt_of_le_of_ne hS_pos h_S_ne_zero
      rw [abs_of_neg hS_neg]
      have h_Î±S_neg : Î± * S < 0 := mul_neg_of_pos_of_neg hÎ±_pos hS_neg
      rw [abs_of_neg (Activation.tanh_neg_of_neg h_Î±S_neg)]
      rw [â† tanh_neg]
      congr 1
      ring
  rw [h_tanh_abs]
  -- Now show tanh(Î±|S|) > Î¸
  -- Key: We have the hypothesis hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸)
  -- Since |S| > Î¸ (from hS), we have Î±|S| > Î±Î¸ (by h_Î±S_bound)
  -- By strict monotonicity of tanh: tanh(Î±|S|) > tanh(Î±Î¸) > Î¸ (by hÎ¸_below_fp)
  have h_tanh_mono := Activation.tanh_strictMono
  -- tanh(Î±|S|) > tanh(Î±Î¸) since Î±|S| > Î±Î¸
  have h_tanh_strict : tanh (Î± * Î¸) < tanh (Î± * |S|) := h_tanh_mono h_Î±S_bound
  -- Combine: Î¸ < tanh(Î±Î¸) < tanh(Î±|S|)
  calc Î¸ < tanh (Î± * Î¸) := hÎ¸_below_fp
    _ < tanh (Î± * |S|) := h_tanh_strict

/-! ## Part 5: Perturbation Robustness -/

/-- A latched state persists even under small perturbations.
    If |S| is large enough (|S| > 1.6) and we apply a small input perturbation Î´,
    the new state tanh(Î±S + Î´) is still close to 1.

    Key insight: artanh(0.9) â‰ˆ 1.47, so we need |Î±S + Î´| > 1.47 to get |tanh(Î±S+Î´)| > 0.9.
    With |S| > 1.6 and Î± â‰¥ 1, we have |Î±S| > 1.6.
    With |Î´| < 0.1, we get |Î±S + Î´| â‰¥ |Î±S| - |Î´| > 1.6 - 0.1 = 1.5 > 1.47. -/
theorem latched_state_robust (Î± S : â„) (Î´_max : â„)
    (hÎ± : 1 â‰¤ Î±) (_hÎ±_lt : Î± < 2)
    (hS : |S| > 1.6) (hÎ´ : Î´_max < 0.1)
    (Î´ : â„) (hÎ´_bound : |Î´| â‰¤ Î´_max) :
    |tanh (Î± * S + Î´)| > 0.9 := by
  -- The key numerical fact is that tanh is strictly increasing and tanh(1.5) > 0.9.
  -- With |Î±S + Î´| > 1.5, we get |tanh(Î±S + Î´)| > 0.9 by monotonicity of |tanh|.
  -- First establish |Î±S + Î´| > 1.5
  have h_Î±S_abs : |Î± * S| â‰¥ |S| := by
    rw [abs_mul]
    have hÎ±_pos : 0 < Î± := by linarith
    rw [abs_of_pos hÎ±_pos]
    calc Î± * |S| â‰¥ 1 * |S| := by nlinarith
      _ = |S| := one_mul _
  have h_Î´_abs : |Î´| < 0.1 := by linarith [hÎ´_bound]
  have h_arg_lower : |Î± * S + Î´| > 1.5 := by
    -- Use reverse triangle inequality: ||a| - |b|| â‰¤ |a + b|
    have h_triangle : |Î± * S| - |Î´| â‰¤ |Î± * S + Î´| := by
      have := abs_abs_sub_abs_le_abs_sub (Î± * S) (-Î´)
      simp only [abs_neg, sub_neg_eq_add] at this
      have h2 : |Î± * S| - |Î´| â‰¤ abs (|Î± * S| - |Î´|) := le_abs_self _
      linarith
    have h2 : |Î± * S| - |Î´| > 1.6 - 0.1 := by
      have : |Î± * S| > 1.6 := lt_of_lt_of_le hS h_Î±S_abs
      linarith
    linarith
  -- Now use NumericalBounds.tanh_ge_15_gt_090 with monotonicity
  rcases le_or_gt (Î± * S + Î´) 0 with hneg | hpos
  Â· -- Case: Î± * S + Î´ â‰¤ 0, so -(Î± * S + Î´) â‰¥ 1.5
    have h_neg_ge : -(Î± * S + Î´) â‰¥ 1.5 := by
      have : |Î± * S + Î´| = -(Î± * S + Î´) := abs_of_nonpos hneg
      linarith
    have h_tanh_neg : tanh (-(Î± * S + Î´)) > 0.90 := NumericalBounds.tanh_ge_15_gt_090 _ h_neg_ge
    rw [Real.tanh_neg] at h_tanh_neg
    have h_abs : |tanh (Î± * S + Î´)| = -tanh (Î± * S + Î´) := by
      have htanh_neg : tanh (Î± * S + Î´) â‰¤ 0 := by
        rcases eq_or_lt_of_le hneg with heq | hlt
        Â· rw [heq]; exact le_of_eq tanh_zero
        Â· exact le_of_lt (Activation.tanh_neg_of_neg hlt)
      exact abs_of_nonpos htanh_neg
    rw [h_abs]
    linarith
  Â· -- Case: Î± * S + Î´ > 0, so Î± * S + Î´ > 1.5
    have h_pos_ge : Î± * S + Î´ â‰¥ 1.5 := by
      have : |Î± * S + Î´| = Î± * S + Î´ := abs_of_pos hpos
      linarith
    have h_tanh_pos : tanh (Î± * S + Î´) > 0.90 := NumericalBounds.tanh_ge_15_gt_090 _ h_pos_ge
    have h_abs : |tanh (Î± * S + Î´)| = tanh (Î± * S + Î´) := by
      apply abs_of_pos
      exact Activation.tanh_pos_of_pos hpos
    rw [h_abs]
    linarith

/-- Main perturbation theorem: starting from an alert state, small inputs
    cannot knock the state out of the alert region. -/
theorem alert_persists_under_perturbation (Î± Î¸ : â„) (Î´_max : â„)
    (hÎ± : 1 < Î±) (hÎ±_lt : Î± < 2)
    (hÎ¸ : 0 < Î¸) (hÎ¸_lt : Î¸ < 0.8)
    (hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸))
    (hÎ´ : Î´_max < (1 - Î¸) / 2)
    (S : â„) (hS_alert : isAlert S Î¸) (Î´ : â„) (hÎ´_bound : |Î´| â‰¤ Î´_max) :
    isAlert (tanh (Î± * S + Î´)) (Î¸ - Î´_max) := by
  simp only [isAlert] at hS_alert âŠ¢
  -- We have |S| > Î¸
  -- Need to show Î¸ - Î´_max < |tanh(Î±S + Î´)|
  -- Key: tanh is 1-Lipschitz, so |tanh(Î±S+Î´) - tanh(Î±S)| â‰¤ |Î´| â‰¤ Î´_max
  -- From forward invariance (informal): |tanh(Î±S)| > Î¸
  -- So |tanh(Î±S + Î´)| > |tanh(Î±S)| - Î´_max > Î¸ - Î´_max
  have h_lip := Activation.tanh_lipschitz
  have h_diff : |tanh (Î± * S + Î´) - tanh (Î± * S)| â‰¤ 1 * |Î± * S + Î´ - Î± * S| := by
    have := LipschitzWith.dist_le_mul h_lip (Î± * S + Î´) (Î± * S)
    rwa [NNReal.coe_one, dist_eq_norm, dist_eq_norm] at this
  simp only [add_sub_cancel_left, one_mul] at h_diff
  -- |tanh(Î±S + Î´) - tanh(Î±S)| â‰¤ |Î´| â‰¤ Î´_max
  have h_pert : |tanh (Î± * S + Î´) - tanh (Î± * S)| â‰¤ Î´_max :=
    le_trans h_diff hÎ´_bound
  -- Need: |tanh(Î±S)| > Î¸ (forward invariance)
  have h_forward : Î¸ < |tanh (Î± * S)| := by
    have := alert_forward_invariant Î± Î¸ hÎ± hÎ¸ hÎ¸_lt hÎ¸_below_fp S hS_alert
    simp only [isAlert, tanhRecur] at this
    exact this
  -- Triangle inequality: |tanh(Î±S+Î´)| â‰¥ |tanh(Î±S)| - |tanh(Î±S+Î´) - tanh(Î±S)|
  have h_triangle : |tanh (Î± * S)| - |tanh (Î± * S + Î´) - tanh (Î± * S)| â‰¤ |tanh (Î± * S + Î´)| := by
    have := abs_sub_abs_le_abs_sub (tanh (Î± * S)) (tanh (Î± * S + Î´))
    linarith [abs_sub_comm (tanh (Î± * S + Î´)) (tanh (Î± * S))]
  calc Î¸ - Î´_max < |tanh (Î± * S)| - Î´_max := by linarith
    _ â‰¤ |tanh (Î± * S)| - |tanh (Î± * S + Î´) - tanh (Î± * S)| := by linarith [h_pert]
    _ â‰¤ |tanh (Î± * S + Î´)| := h_triangle

/-! ## Part 6: Linear Systems Cannot Latch -/

/-- Linear recurrence: S_{t+1} = Î±Â·S_t (no input). -/
def linearRecur (Î± : â„) (S : â„) : â„ := Î± * S

/-- Iterated linear recurrence. -/
def linearRecurIter (Î± : â„) : â„• â†’ â„ â†’ â„
  | 0, S => S
  | n + 1, S => linearRecur Î± (linearRecurIter Î± n S)

/-- Linear iteration is just Î±^n Â· S. -/
theorem linearRecurIter_eq_pow (Î± : â„) (n : â„•) (S : â„) :
    linearRecurIter Î± n S = Î± ^ n * S := by
  induction n with
  | zero => simp [linearRecurIter]
  | succ n ih =>
    simp only [linearRecurIter, linearRecur, ih]
    ring

/-- Linear systems have only one fixed point: 0 (for Î± â‰  1).
    For Î± = 1, all points are fixed (trivial case). -/
theorem linear_fixed_point_is_zero (Î± : â„) (hÎ± : Î± â‰  1) (S : â„)
    (hfp : linearRecur Î± S = S) : S = 0 := by
  simp only [linearRecur] at hfp
  -- Î±S = S â†’ (Î± - 1)S = 0
  have h : (Î± - 1) * S = 0 := by linarith
  rcases mul_eq_zero.mp h with h_coef | h_S
  Â· -- h_coef : Î± - 1 = 0, i.e., Î± = 1, contradicts hÎ±
    have : Î± = 1 := by linarith
    exact absurd this hÎ±
  Â· exact h_S

/-- For |Î±| < 1, linear states decay to 0.
    This is the fundamental contrast with tanh latching. -/
theorem linear_state_decays (Î± : â„) (hÎ± : |Î±| < 1) (S : â„) :
    Tendsto (fun n => linearRecurIter Î± n S) atTop (nhds 0) := by
  simp only [linearRecurIter_eq_pow]
  have h_pow : Tendsto (fun n => Î± ^ n) atTop (nhds 0) :=
    tendsto_pow_atTop_nhds_zero_of_abs_lt_one hÎ±
  have h_mul : Tendsto (fun n => Î± ^ n * S) atTop (nhds (0 * S)) :=
    h_pow.mul_const S
  simp only [zero_mul] at h_mul
  exact h_mul

/-- For |Î±| > 1, linear states explode to Â±âˆ (unless S = 0).
    This is also not latching - it's instability. -/
theorem linear_state_explodes (Î± : â„) (hÎ± : 1 < |Î±|) (S : â„) (hS : S â‰  0) :
    Â¬ âˆƒ L : â„, Tendsto (fun n => linearRecurIter Î± n S) atTop (nhds L) := by
  simp only [linearRecurIter_eq_pow]
  intro âŸ¨L, hLâŸ©
  -- |Î±^n Â· S| = |Î±|^n Â· |S| â†’ âˆ
  have h_exp : Tendsto (fun n => |Î±|^n) atTop atTop :=
    tendsto_pow_atTop_atTop_of_one_lt hÎ±
  have h_mul : Tendsto (fun n => |Î±|^n * |S|) atTop atTop := by
    have hS_pos : 0 < |S| := abs_pos.mpr hS
    exact Tendsto.atTop_mul_const hS_pos h_exp
  -- |Î±^n Â· S| = |Î±|^n Â· |S| â†’ âˆ
  have h_abs_eq : âˆ€ n, |Î± ^ n * S| = |Î±|^n * |S| := fun n => by
    rw [abs_mul, abs_pow]
  -- The sequence |Î±^n Â· S| â†’ âˆ
  have h_abs_tendsto : Tendsto (fun n => |Î± ^ n * S|) atTop atTop := by
    simp only [h_abs_eq]
    exact h_mul
  -- Convergent sequences are bounded, but |Î±^n Â· S| â†’ âˆ is unbounded
  -- This is a contradiction
  -- Proof: If Î±^n * S â†’ L, then |Î±^n * S| is eventually bounded by |L| + 1
  -- But |Î±^n * S| â†’ âˆ means it eventually exceeds any bound
  have h_eventually_large := Filter.Tendsto.eventually_gt_atTop h_abs_tendsto (|L| + 1)
  rw [Filter.eventually_atTop] at h_eventually_large
  obtain âŸ¨N, hNâŸ© := h_eventually_large
  -- Also, Î±^n * S â†’ L means |Î±^n * S - L| < 1 eventually
  have h_eventually_close := Metric.tendsto_atTop.mp hL 1 (by norm_num : (0 : â„) < 1)
  obtain âŸ¨M, hMâŸ© := h_eventually_close
  -- At max(N, M), both conditions hold
  specialize hN (max N M) (le_max_left N M)
  specialize hM (max N M) (le_max_right N M)
  rw [Real.dist_eq] at hM
  -- |Î±^{max(N,M)} * S| > |L| + 1 and |Î±^{max(N,M)} * S - L| < 1
  have h1 : |Î± ^ max N M * S| â‰¤ |Î± ^ max N M * S - L| + |L| := by
    have := abs_sub_abs_le_abs_sub (Î± ^ max N M * S) L
    linarith
  linarith

/-- Summary: Linear systems cannot latch.
    For |Î±| < 1: states decay to 0 (no memory retention)
    For |Î±| > 1: states explode (instability, not latching)
    For Î± = 1: states are static (no processing, just storing)
    None of these is "latching" - stable retention at a nonzero fixed point. -/
theorem linear_cannot_latch (Î± : â„) (Sâ‚€ : â„) (hSâ‚€ : Sâ‚€ â‰  0) :
    (|Î±| < 1 â†’ Tendsto (fun n => linearRecurIter Î± n Sâ‚€) atTop (nhds 0)) âˆ§
    (1 < |Î±| â†’ Â¬ âˆƒ L : â„, Tendsto (fun n => linearRecurIter Î± n Sâ‚€) atTop (nhds L)) âˆ§
    (Î± = 1 â†’ âˆ€ n, linearRecurIter Î± n Sâ‚€ = Sâ‚€) := by
  constructor
  Â· intro h; exact linear_state_decays Î± h Sâ‚€
  constructor
  Â· intro h; exact linear_state_explodes Î± h Sâ‚€ hSâ‚€
  Â· intro h_eq_one n
    rw [linearRecurIter_eq_pow, h_eq_one, one_pow, one_mul]

/-! ## Part 7: Main Attention Persistence Theorem -/

/-- **Main Theorem**: E88 heads can enter and persist in an "alert" state.

    This theorem captures the essence of attention persistence:

    1. **Entry**: For Î± > 1, there exist stable fixed points S* with |S*| close to 1
    2. **Persistence**: States near these fixed points remain near them (attraction)
    3. **Robustness**: Small perturbations don't knock states out of the alert region
    4. **Contrast**: Linear systems cannot achieve this - they decay or explode

    This is why E88 can "pay attention" to a pattern and remember it,
    while linear recurrent models (like Mamba2's within-layer dynamics) cannot.

    CRITICAL: The hypothesis Î¸ < tanh(Î± * Î¸) ensures Î¸ is below the fixed point S*(Î±).
    This is necessary for the alert basin to be non-empty and forward invariant. -/
theorem attention_persistence_main (Î± Î¸ : â„) (hÎ± : 1 < Î±) (hÎ±_lt : Î± < 2)
    (hÎ¸ : 0 < Î¸) (hÎ¸_lt : Î¸ < 0.8) (hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸)) :
    -- Part 1: Nonzero fixed points exist
    (âˆƒ S_star : â„, S_star â‰  0 âˆ§ isFixedPoint Î± S_star) âˆ§
    -- Part 2: Alert basin is non-empty
    (âˆƒ S : â„, S âˆˆ alertBasin Î± Î¸) âˆ§
    -- Part 3: Alert states are forward invariant
    (âˆ€ S, isAlert S Î¸ â†’ isAlert (tanhRecur Î± S) Î¸) âˆ§
    -- Part 4: Linear systems decay (contrast)
    (âˆ€ Î² : â„, |Î²| < 1 â†’ âˆ€ S, Tendsto (fun n => linearRecurIter Î² n S) atTop (nhds 0)) := by
  constructor
  Â· exact nonzero_fixed_point_exists Î± hÎ±
  constructor
  Â· have hÎ¸_lt' : Î¸ < 1 := by linarith
    exact alert_basin_nonempty Î± Î¸ hÎ± hÎ¸ hÎ¸_lt' hÎ¸_below_fp
  constructor
  Â· exact alert_forward_invariant Î± Î¸ hÎ± hÎ¸ hÎ¸_lt hÎ¸_below_fp
  Â· intro Î² hÎ² S
    exact linear_state_decays Î² hÎ² S

/-! ## Part 8: E88 Head Alert State Persistence -/

/-- E88 head state update with input: S' = tanh(Î±Â·S + Î´Â·input). -/
noncomputable def e88HeadUpdate (Î± Î´ : â„) (S input : â„) : â„ := tanh (Î± * S + Î´ * input)

/-- An E88 head can enter alert mode when it sees a strong input.

    NOTE: Requires |S| â‰¤ 1 (tanh-bounded state) so that Î±Â·S doesn't dominate.
    The constraint Î¸ < 0.76 ensures tanh(1) > Î¸, guaranteeing alertness
    when arg > 1. For Î¸ âˆˆ [0.76, 1), we'd need Î´Â·input > artanh(Î¸) + Î±|S|,
    which is a stronger input requirement. -/
theorem e88_head_can_enter_alert (Î± Î´ Î¸ : â„) (S : â„)
    (hÎ± : 0 < Î±) (hÎ±_lt : Î± < 2) (hÎ´ : 0 < Î´) (hÎ¸ : 0 < Î¸) (hÎ¸_lt : Î¸ < 0.76)
    (hS_bounded : |S| â‰¤ 1)
    (input : â„) (h_strong : Î´ * input > Î¸ + 1 + Î±) :
    isAlert (e88HeadUpdate Î± Î´ S input) Î¸ := by
  simp only [isAlert, e88HeadUpdate]
  -- With the new hypotheses:
  -- - |S| â‰¤ 1, so Î±*S â‰¥ -Î± (since Î± > 0)
  -- - Î´*input > Î¸ + 1 + Î±
  -- Therefore arg = Î±*S + Î´*input > -Î± + (Î¸ + 1 + Î±) = Î¸ + 1 > 1
  -- Since arg > 1 and Î¸ < 0.76 < tanh(1), we have tanh(arg) > tanh(1) > 0.76 > Î¸
  have hÎ±_pos : 0 < Î± := hÎ±
  have h_Î±S_lower : -Î± â‰¤ Î± * S := by
    have h1 : -(|S|) â‰¤ S := neg_abs_le S
    have hS1 : -1 â‰¤ -|S| := by linarith [hS_bounded]
    have h2 : Î± * (-1) â‰¤ Î± * (-|S|) := mul_le_mul_of_nonneg_left hS1 (le_of_lt hÎ±_pos)
    have h3 : Î± * (-|S|) â‰¤ Î± * S := mul_le_mul_of_nonneg_left h1 (le_of_lt hÎ±_pos)
    have h4 : -Î± = Î± * (-1) := by ring
    linarith
  have h_arg_lower : Î¸ + 1 < Î± * S + Î´ * input := by
    -- From h_strong: Î´ * input > Î¸ + 1 + Î±
    -- From h_Î±S_lower: -Î± â‰¤ Î± * S, i.e., Î± * S â‰¥ -Î±
    -- So Î± * S + Î´ * input > -Î± + (Î¸ + 1 + Î±) = Î¸ + 1
    have h1 : Î´ * input + Î± * S > (Î¸ + 1 + Î±) + (-Î±) := by linarith [h_strong, h_Î±S_lower]
    linarith
  have h_arg_gt_one : 1 < Î± * S + Î´ * input := by linarith
  have h_arg_pos : 0 < Î± * S + Î´ * input := by linarith
  have h_tanh_pos := Activation.tanh_pos_of_pos h_arg_pos
  rw [abs_of_pos h_tanh_pos]
  -- Now use tanh(arg) > tanh(1) > 0.76 > Î¸
  have h_tanh_mono := Activation.tanh_strictMono
  have h_tanh_gt_one : tanh 1 < tanh (Î± * S + Î´ * input) := h_tanh_mono h_arg_gt_one
  have h_tanh_076 := tanh_gt_076_of_ge_one (Î± * S + Î´ * input) (le_of_lt h_arg_gt_one)
  linarith

/-- Once in alert mode, an E88 head stays in alert mode under small inputs.
    This is the formalization of attention persistence.

    CRITICAL: Requires Î¸ < tanh(Î± * Î¸) to ensure alert states persist. -/
theorem e88_head_stays_alert (Î± Î´ Î¸ : â„) (S : â„)
    (hÎ± : 1 < Î±) (hÎ±_lt : Î± < 2) (hÎ´ : |Î´| < 0.1) (hÎ¸ : 0 < Î¸) (hÎ¸_lt : Î¸ < 0.8)
    (hÎ¸_below_fp : Î¸ < tanh (Î± * Î¸))
    (hS_alert : isAlert S Î¸)
    (input : â„) (h_input_small : |input| â‰¤ 1) :
    isAlert (e88HeadUpdate Î± Î´ S input) (Î¸ - |Î´|) := by
  simp only [e88HeadUpdate]
  -- Apply alert_persists_under_perturbation with perturbation Î´Â·input
  have h_pert_bound : |Î´ * input| â‰¤ |Î´| := by
    calc |Î´ * input| = |Î´| * |input| := abs_mul Î´ input
      _ â‰¤ |Î´| * 1 := mul_le_mul_of_nonneg_left h_input_small (abs_nonneg Î´)
      _ = |Î´| := mul_one |Î´|
  have hÎ´_small : |Î´| < (1 - Î¸) / 2 := by
    have h1 : (0.1 : â„) = (1 - 0.8) / 2 := by norm_num
    have h2 : (1 - 0.8 : â„) / 2 < (1 - Î¸) / 2 := by
      apply div_lt_div_of_pos_right _ (by norm_num : (0 : â„) < 2)
      linarith
    linarith
  exact alert_persists_under_perturbation Î± Î¸ |Î´| hÎ± hÎ±_lt hÎ¸ hÎ¸_lt hÎ¸_below_fp hÎ´_small S hS_alert
    (Î´ * input) h_pert_bound

/-! ## Part 9: Summary Comparison -/

/-- **Summary Theorem**: The fundamental capability gap between E88 and linear systems.

    E88 (with tanh):
    - Has stable nonzero fixed points (for Î± > 1)
    - Can enter and maintain alert states
    - Robust to small perturbations

    Linear systems:
    - Only fixed point is 0 (for Î± â‰  1)
    - States either decay (|Î±| < 1) or explode (|Î±| > 1)
    - Cannot maintain stable nonzero states

    This is why E88 can implement "attention persistence" while linear models cannot.
-/
theorem e88_vs_linear_attention_persistence :
    -- E88 property: nonzero fixed points exist for Î± > 1
    (âˆ€ Î± : â„, 1 < Î± â†’ âˆƒ S : â„, S â‰  0 âˆ§ isFixedPoint Î± S) âˆ§
    -- Linear property: only 0 is fixed for Î± â‰  1
    (âˆ€ Î± : â„, Î± â‰  1 â†’ âˆ€ S : â„, linearRecur Î± S = S â†’ S = 0) âˆ§
    -- Linear property: states decay for |Î±| < 1
    (âˆ€ Î± : â„, |Î±| < 1 â†’ âˆ€ S : â„, Tendsto (fun n => linearRecurIter Î± n S) atTop (nhds 0)) := by
  constructor
  Â· exact nonzero_fixed_point_exists
  constructor
  Â· exact linear_fixed_point_is_zero
  Â· exact linear_state_decays

end AttentionPersistence
